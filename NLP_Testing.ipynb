{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShotaroBaba/NLP_Practice/blob/master/NLP_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsHMmbPjhpF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spacy is the package that allows you to do Natural Language Processing very easily. \n",
        "\n",
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP0GfU3Mh3up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Firstly, loading the language package is necessary to evaluate the texts for finding the software\n",
        "import subprocess\n",
        "\n",
        "# At this time, I loaded the small size English model data.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BevpC0DBjTk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is how the model is loaded.\n",
        "processed_data = nlp((\"Spacy is the package that allows you to do Natural Language Processing very easily.\" \n",
        "     \" Firstly, loading the language package is necessary to evaluate the texts for finding the software.\"\n",
        "     \" At this time, I loaded the small size English model data.\"\n",
        "     \" This is how the model is loaded.\"\n",
        "     \" Print the text so that you can see the contents.\"\n",
        "     \" After generating the result, the text and the type of tokens are shown below:\"\n",
        "     \" In my case, I only take NOUN, VERB and ADJ.\"\n",
        "     \" This allows you to create an easy method to analyze your language model.\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZzrPRGSmVNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4119b573-2f9d-4c70-ac52-412dc43c99fe"
      },
      "source": [
        "# Print the text so that you can see the contents.\n",
        "processed_data.text"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spacy is the package that allows you to do Natural Language Processing very easily. Firstly, loading the language package is necessary to evaluate the texts for finding the software. At this time, I loaded the small size English model data. This is how the model is loaded. Print the text so that you can see the contents. After generating the result, the text and the type of tokens are shown below: In my case, I only take NOUN, VERB and ADJ.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhb4Zaw1m-Av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "045f02b3-73da-4353-9ca1-97da0a5eb4d4"
      },
      "source": [
        "# After generating the result, the text and the type of tokens are shown below:\n",
        "for token in processed_data[:10]:\n",
        "    print(token.text, token.pos_, token.dep_)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy NOUN nsubj\n",
            "is VERB ROOT\n",
            "the DET det\n",
            "package NOUN attr\n",
            "that DET nsubj\n",
            "allows VERB relcl\n",
            "you PRON nsubj\n",
            "to PART aux\n",
            "do VERB ccomp\n",
            "Natural PROPN compound\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtjHKruWnqKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "e748b6b9-3d49-43da-bcd0-61e3c7f6ce7a"
      },
      "source": [
        "# In my case, I only take NOUN, VERB and ADJ.\n",
        "processed_data = [token for token in processed_data if token.pos_ in [\"VERB\", \"NOUN\", \"ADJ\"]]\n",
        "for token in processed_data[:20]:\n",
        "  print(token.text, token.pos_, token.dep_)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy NOUN nsubj\n",
            "is VERB ROOT\n",
            "package NOUN attr\n",
            "allows VERB relcl\n",
            "do VERB ccomp\n",
            "loading VERB csubj\n",
            "language NOUN compound\n",
            "package NOUN dobj\n",
            "is VERB ROOT\n",
            "necessary ADJ acomp\n",
            "evaluate VERB xcomp\n",
            "texts NOUN dobj\n",
            "finding VERB pcomp\n",
            "software NOUN dobj\n",
            "time NOUN pobj\n",
            "loaded VERB ROOT\n",
            "small ADJ amod\n",
            "size NOUN dobj\n",
            "English ADJ compound\n",
            "model NOUN compound\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGPDme4yp1_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This allows you to create an easy method to analyze your language model."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}