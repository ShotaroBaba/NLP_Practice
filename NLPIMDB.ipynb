{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPIMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShotaroBaba/NLP_Practice/blob/NLP_smaller_dataset/NLPIMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k02zSz6nO218",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Firstly, download text dataset.:\n",
        "import os\n",
        "import gensim\n",
        "import requests \n",
        "from gensim.parsing.preprocessing import stem\n",
        "from gensim.parsing.preprocessing import strip_punctuation\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "urlToWiki = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "savedFileName = 'aclImdb_v1.tar.gz'\n",
        "if not os.path.isfile(savedFileName):\n",
        "  with open(savedFileName,'wb') as output:\n",
        "    output.write(requests.get(urlToWiki).content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbtusP0NRdBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "\n",
        "# Extract tar.gz file\n",
        "tarfile.open(savedFileName, \"r:gz\").extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebdtqv55SCMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_test = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/test/neg/\", topdown=False) for x in files if x.endswith(\".txt\") ]\n",
        "pos_test  = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/test/pos/\", topdown=False) for x in files if x.endswith(\".txt\") ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_JXhEaf_iIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b16a43e3-5519-4029-c9dd-55de1f7d00e2"
      },
      "source": [
        "print(neg_test[:10])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aclImdb/test/neg/5408_1.txt', 'aclImdb/test/neg/10830_1.txt', 'aclImdb/test/neg/10039_1.txt', 'aclImdb/test/neg/1777_4.txt', 'aclImdb/test/neg/6750_4.txt', 'aclImdb/test/neg/2079_1.txt', 'aclImdb/test/neg/9_4.txt', 'aclImdb/test/neg/1449_4.txt', 'aclImdb/test/neg/7144_4.txt', 'aclImdb/test/neg/3739_2.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjgCeD_FSNMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_train = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/train/neg/\", topdown=False) for x in files if x.endswith(\".txt\")]\n",
        "pos_train  =[os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/train/pos/\", topdown=False) for x in files if x.endswith(\".txt\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9akqc_v3_vwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return texts from path\n",
        "# if the text is too short, then it will omit it. \n",
        "def fetch_text(path):\n",
        "  with open(path) as f:\n",
        "    text = f.read()\n",
        "    if len(text.split()) < 50:\n",
        "      return False\n",
        "    else:\n",
        "      return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbsG16e3_z-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, the files are retrieved as the list of texts.\n",
        "neg_test = list(filter(None, [fetch_text(x) for x in neg_test]))\n",
        "pos_test = list(filter(None, [fetch_text(x) for x in pos_test]))\n",
        "neg_train = list(filter(None, [fetch_text(x) for x in neg_train]))\n",
        "pos_train = list(filter(None, [fetch_text(x) for x in pos_train]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ZA56ONHdFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aggregate all lists into one:\n",
        "\n",
        "all_text = neg_test + pos_test + neg_train + pos_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nde8HDsDCafC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-process these given texts, by removing stop words and stemming.\n",
        "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_short\n",
        "stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
        "all_text_processed = [preprocess_string(x.lower(), filters = [strip_tags, strip_short, strip_punctuation, strip_multiple_whitespaces]) for x in all_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2AEh3L-IXHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display how one of them is pre-processed:\n",
        "\n",
        "all_text_processed = [[x for x in str_list if len(x) > 1 and not x in stopwords] for str_list in all_text_processed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d38T1sDeJMES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "45c41d1a-122f-419f-f98c-0f453762c18a"
      },
      "source": [
        "print(all_text_processed[0])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['casper', 'van', 'dien', 'michael', 'rooker', 'generally', 'relegated', 'movies', 'movie', 'fails', 'convey', 'slightest', 'sense', 'excitement', 'fear', 'dread', 'count', 'dread', 'sitting', 'rest', 'garbage', 'direction', 'amateurish', 'annoying', 'cuts', 'jerky', 'movement', 'hides', 'fact', 'killer', 'near', 'victims', 'attacks', 'killer', 'cheap', 'skull', 'mask', 'black', 'hood', 'liked', 'better', 'fighting', 'man', 'laziest', 'jobs', 'character', 'design', 've', 'seen', 'mean', 'skeletor', 'horse', 'supposed', 'scary', 'supernatural', 'creature', 'supposed', 'seriously', 'scenes', 'dude', 'riding', 'woods', 'horse', 'barely', 'stay', 'interspersed', 'scenes', 'soldiers', 'shooting', 'randomly', 'woods', 'thinking', 'shoot', 'ghost', 'occasionally', 'skeletor', 'shoot', 'arrow', 'ride', 'stab', 'revealing', 'corny', 'effects', 'generally', 'enjoy', 'sci', 'channel', 'fare', 'basic', 'cheese', 'level', 'film', 'inept', 'level', 'enjoyment', 'dolph', 'lundgren', 'need']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5lU_gwrJW43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionary & BOW:\n",
        "dictionary = Dictionary(all_text_processed)\n",
        "corpus = [dictionary.doc2bow(x) for x in all_text_processed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvrsNDk3KdCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_imdb = gensim.models.LdaMulticore(corpus, id2word=dictionary, num_topics=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhNIPWTLKivo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "53cb11f2-0432-4e32-e428-a1af49d4d448"
      },
      "source": [
        "# You can see that the topic is all about movie and drama series.\n",
        "\n",
        "lda_imdb.show_topics()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.013*\"movie\" + 0.011*\"like\" + 0.007*\"good\" + 0.006*\"time\" + 0.006*\"funny\" + 0.005*\"series\" + 0.004*\"great\" + 0.004*\"comedy\" + 0.004*\"episode\" + 0.003*\"best\"'),\n",
              " (1,\n",
              "  '0.036*\"movie\" + 0.011*\"like\" + 0.008*\"people\" + 0.007*\"good\" + 0.007*\"film\" + 0.006*\"horror\" + 0.006*\"movies\" + 0.006*\"bad\" + 0.004*\"think\" + 0.004*\"story\"'),\n",
              " (2,\n",
              "  '0.011*\"film\" + 0.004*\"films\" + 0.004*\"time\" + 0.003*\"like\" + 0.003*\"best\" + 0.003*\"movie\" + 0.003*\"good\" + 0.003*\"years\" + 0.003*\"way\" + 0.002*\"people\"'),\n",
              " (3,\n",
              "  '0.015*\"film\" + 0.005*\"story\" + 0.005*\"life\" + 0.004*\"man\" + 0.004*\"love\" + 0.004*\"young\" + 0.003*\"like\" + 0.003*\"time\" + 0.003*\"character\" + 0.003*\"great\"'),\n",
              " (4,\n",
              "  '0.030*\"film\" + 0.028*\"movie\" + 0.011*\"good\" + 0.009*\"like\" + 0.008*\"great\" + 0.008*\"story\" + 0.007*\"time\" + 0.005*\"think\" + 0.005*\"watch\" + 0.005*\"seen\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_60yMDTuNUwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "944205f1-cbc7-4d32-a279-4841d25a240b"
      },
      "source": [
        "dictionary"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x7fdc00327710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzVwgAkcNVXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count numbers of words in corpus.\n",
        "def count_words_in_corpus(corpus):\n",
        "  count_dict = Counter() \n",
        "  for word_count in corpus:\n",
        "    for key, value in word_count:\n",
        "      count_dict.update({dictionary[key] : value})\n",
        "\n",
        "  return count_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVazZ5iGZsuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_of_words = count_words_in_corpus(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3chj-isJaB4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_count = sorted(count_of_words.items(), key = lambda x: x[1], reverse = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAzsNiu7cb-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c92b8a6e-57f5-47a9-9587-641af5c225c0"
      },
      "source": [
        "print(\"\\n\".join([str(x) for x in sorted_count[:20]]))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('movie', 87076)\n",
            "('film', 79252)\n",
            "('like', 39981)\n",
            "('good', 29489)\n",
            "('time', 24923)\n",
            "('story', 22941)\n",
            "('bad', 18248)\n",
            "('people', 18109)\n",
            "('great', 17878)\n",
            "('way', 15592)\n",
            "('movies', 15154)\n",
            "('characters', 14360)\n",
            "('think', 14270)\n",
            "('character', 13859)\n",
            "('watch', 13807)\n",
            "('films', 13699)\n",
            "('seen', 13231)\n",
            "('love', 12913)\n",
            "('life', 12867)\n",
            "('plot', 12851)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ExTiDhOKVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# References\n",
        "# Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. \n",
        "# The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011)."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}