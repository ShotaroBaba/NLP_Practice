{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPIMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShotaroBaba/NLP_Practice/blob/NLP_smaller_dataset/NLPIMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k02zSz6nO218",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Firstly, download text dataset.:\n",
        "# This time, IMDB comment dataset has been used for the experiment.\n",
        "import os\n",
        "import gensim\n",
        "import requests \n",
        "from gensim.parsing.preprocessing import stem\n",
        "from gensim.parsing.preprocessing import strip_punctuation\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "urlToWiki = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "savedFileName = 'aclImdb_v1.tar.gz'\n",
        "if not os.path.isfile(savedFileName):\n",
        "  with open(savedFileName,'wb') as output:\n",
        "    output.write(requests.get(urlToWiki).content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbtusP0NRdBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "\n",
        "# Extract tar.gz file\n",
        "tarfile.open(savedFileName, \"r:gz\").extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebdtqv55SCMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_test = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/test/neg/\", topdown=False) for x in files if x.endswith(\".txt\") ]\n",
        "pos_test  = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/test/pos/\", topdown=False) for x in files if x.endswith(\".txt\") ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_JXhEaf_iIi",
        "colab_type": "code",
        "outputId": "17a4336f-219b-45f8-ac44-996559d0b012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(neg_test[:10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aclImdb/test/neg/4332_2.txt', 'aclImdb/test/neg/3195_2.txt', 'aclImdb/test/neg/7053_1.txt', 'aclImdb/test/neg/9996_2.txt', 'aclImdb/test/neg/3744_4.txt', 'aclImdb/test/neg/1708_1.txt', 'aclImdb/test/neg/7690_3.txt', 'aclImdb/test/neg/11833_4.txt', 'aclImdb/test/neg/11344_1.txt', 'aclImdb/test/neg/5580_1.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjgCeD_FSNMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_train = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/train/neg/\", topdown=False) for x in files if x.endswith(\".txt\")]\n",
        "pos_train  =[os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/train/pos/\", topdown=False) for x in files if x.endswith(\".txt\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9akqc_v3_vwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return texts from path\n",
        "# if the text is too short, then it will omit it. \n",
        "def fetch_text(path):\n",
        "  with open(path) as f:\n",
        "    text = f.read()\n",
        "    if len(text.split()) < 50:\n",
        "      return False\n",
        "    else:\n",
        "      return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbsG16e3_z-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, the files are retrieved as the list of texts.\n",
        "neg_test = list(filter(None, [fetch_text(x) for x in neg_test]))\n",
        "pos_test = list(filter(None, [fetch_text(x) for x in pos_test]))\n",
        "neg_train = list(filter(None, [fetch_text(x) for x in neg_train]))\n",
        "pos_train = list(filter(None, [fetch_text(x) for x in pos_train]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ZA56ONHdFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aggregate all lists into one:\n",
        "\n",
        "all_text = neg_test + pos_test + neg_train + pos_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koI0oWCjSPZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load another necessary libraries and functions\n",
        "import spacy\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "def lemmatize_sentence(text):\n",
        "  doc = nlp(text)\n",
        "  return \" \".join([token.lemma_ for token in doc])\n",
        "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_short, strip_numeric\n",
        "from collections import Counter\n",
        "stopwords = gensim.parsing.preprocessing.STOPWORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nde8HDsDCafC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-process these given texts, by removing stop words and lemmatization.\n",
        "all_text_processed = [preprocess_string(lemmatize_sentence(x.lower()), \n",
        "                                        filters = [strip_tags, strip_short, \n",
        "                                                   strip_punctuation, strip_multiple_whitespaces]) for x in all_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2AEh3L-IXHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display how one of them is pre-processed:\n",
        "\n",
        "all_text_processed = [[x for x in str_list if len(x) > 1 and not x in stopwords and not x == \"PRON\"] for str_list in all_text_processed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d38T1sDeJMES",
        "colab_type": "code",
        "outputId": "5a9cad2d-0824-4eb9-c988-c2377d9a4022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(all_text_processed[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['wow', 'watch', 'night', 'mccool', 'yesterday', 'wow', 'major', 'spoilers', 'like', 'summary', 'plot', 'stupid', 'pointless', 'movie', 'tell', 'anybody', 'watch', 'inflict', 'pain', 'glimpse', 'huge', 'chunk', 'plot', 'randy', 'work', 'bar', 'mccool', 'meet', 'woman', 'jewel', 'convince', 'surprisingly', 'sex', 'boyfriend', 'end', 'try', 'rob', 'kill', 'randy', 'cousin', 'detective', 'scene', 'crime', 'fall', 'jewel', 'mascot', 'stupidity', 'use', 'guy', 'want', 'involve', 'dvd', 'player', 'randy', 'hire', 'hit', 'man', 'kill', 'eventually', 'detective', 'kill', 'boyfriend', 'psycho', 'brother', 'hit', 'man', 'jewel', 'seriously', 'leave', 'hardly', 'sex', 'scene', 'nearly', 'pornographic', 'scene', 'liv', 'tyl', 'jewel', 'use', 'hose', 'flaunt', 'sexuality', 'point', 'movie', 'honest', 'think', 'producer', 'director', 'male', 'urge', 'think', 'absolutely', 'uncalled', 'plain', 'stupid', 'watch', 'movie', 'want', 'plot', 'want', 'character', 'care', 'sexy', 'woman', 'flaunt', 'happen', 'movie', 'goodness', 'sake', 'bad', 'fight', 'club', 'bad', 'john', 'goodman', 'detective', 'devote', 'high', 'wonder', 'goodman', 'play', 'outrageously', 'pitiful', 'remember', 'brother', 'art', 'thou', 'reputation', 'notch', 'liv', 'tyl', 'amazing', 'actress', 'lord', 'ring', 'series', 'movie', 'unintelligent', 'slut', 'want', 'way', 'reputation', 'seven', 'notch', 'amazed', 'simply', 'amazed', 'people', 'work', 'hard', 'stupid', 'music', 'absolutely', 'crappy', 'ymca', 'play', 'john', 'goodman', 'character', 'kill', 'fit', 'character', 'totally', 'unlikeable', 'plot', 'stupid', 'conceive', 'man', 'fit', 'genre', 'close', 'pornographic', 'comedy', 'suppose', 'funny', 'wasn', 'think', 'rant', 'let', 'assure', 'right', 'mind', 'want', 'movie', 'lust', 'liv', 'tyl', 'character']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5lU_gwrJW43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionary & BOW:\n",
        "dictionary = Dictionary(all_text_processed)\n",
        "corpus = [dictionary.doc2bow(x) for x in all_text_processed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvrsNDk3KdCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_imdb = gensim.models.LdaMulticore(corpus, id2word=dictionary, num_topics=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhNIPWTLKivo",
        "colab_type": "code",
        "outputId": "c2c707b8-c7f4-4998-df1c-b7a5c294d390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# You can see that the topic is all about movie and drama series.\n",
        "\n",
        "lda_imdb.show_topics()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.027*\"film\" + 0.012*\"good\" + 0.011*\"movie\" + 0.006*\"bad\" + 0.005*\"like\" + 0.005*\"scene\" + 0.004*\"look\" + 0.004*\"action\" + 0.004*\"plot\" + 0.004*\"time\"'),\n",
              " (1,\n",
              "  '0.050*\"movie\" + 0.016*\"like\" + 0.015*\"film\" + 0.014*\"good\" + 0.013*\"watch\" + 0.010*\"think\" + 0.010*\"time\" + 0.008*\"bad\" + 0.007*\"great\" + 0.006*\"character\"'),\n",
              " (2,\n",
              "  '0.008*\"good\" + 0.008*\"play\" + 0.008*\"movie\" + 0.007*\"film\" + 0.006*\"great\" + 0.005*\"character\" + 0.005*\"time\" + 0.005*\"role\" + 0.005*\"star\" + 0.005*\"like\"'),\n",
              " (3,\n",
              "  '0.014*\"movie\" + 0.007*\"like\" + 0.007*\"good\" + 0.007*\"film\" + 0.006*\"man\" + 0.006*\"time\" + 0.006*\"love\" + 0.006*\"life\" + 0.005*\"story\" + 0.005*\"character\"'),\n",
              " (4,\n",
              "  '0.035*\"film\" + 0.007*\"story\" + 0.006*\"character\" + 0.005*\"like\" + 0.005*\"time\" + 0.005*\"life\" + 0.005*\"good\" + 0.004*\"work\" + 0.004*\"people\" + 0.004*\"way\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzVwgAkcNVXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count numbers of words in corpus.\n",
        "def count_words_in_corpus(corpus):\n",
        "  count_dict = Counter() \n",
        "  for word_count in corpus:\n",
        "    for key, value in word_count:\n",
        "      count_dict.update({dictionary[key] : value})\n",
        "\n",
        "  return count_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVazZ5iGZsuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_of_words = count_words_in_corpus(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3chj-isJaB4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_count = sorted(count_of_words.items(), key = lambda x: x[1], reverse = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAzsNiu7cb-J",
        "colab_type": "code",
        "outputId": "95fcdcb0-1e67-4018-a766-d5d6770b16c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "print(\"\\n\".join([str(x) for x in sorted_count[:20]]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('movie', 101922)\n",
            "('film', 94644)\n",
            "('like', 43949)\n",
            "('good', 40883)\n",
            "('time', 31142)\n",
            "('character', 27966)\n",
            "('watch', 27346)\n",
            "('bad', 26082)\n",
            "('story', 25046)\n",
            "('think', 23103)\n",
            "('scene', 21149)\n",
            "('great', 19805)\n",
            "('look', 19542)\n",
            "('know', 18990)\n",
            "('people', 18302)\n",
            "('way', 17120)\n",
            "('love', 17003)\n",
            "('play', 16816)\n",
            "('come', 16369)\n",
            "('thing', 16334)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ-P0gxnQEdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_corpus(text_to_be_converted):\n",
        "  all_text_processed = [preprocess_string(lemmatize_sentence(x.lower()), \n",
        "                                          filters = [strip_tags, strip_short, \n",
        "                                                    strip_punctuation, strip_multiple_whitespaces, strip_numeric]) for x in text_to_be_converted]\n",
        "  all_text_processed = [[x for x in str_list if len(x) > 1 and not x in stopwords and not x == \"PRON\"] for str_list in all_text_processed]\n",
        "  count_dict = Counter() \n",
        "  for word_list in all_text_processed:\n",
        "    for word in word_list:\n",
        "      count_dict.update({word: 1})                      \n",
        "  return count_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Hzh3ieRNUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count words for both two sentiment.\n",
        "neg = neg_test + neg_train\n",
        "pos = pos_test + pos_train\n",
        "\n",
        "pos_processed_count = create_corpus(pos)\n",
        "neg_processed_count = create_corpus(neg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrD-wNJISc76",
        "colab_type": "code",
        "outputId": "9f0fac36-1f18-4d03-ff82-aadc59658465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " print(sorted(pos_processed_count.items(), key = lambda x: x[1], reverse = True)[:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('film', 50194), ('movie', 44137), ('good', 22658), ('like', 19922), ('time', 16134), ('great', 14133), ('story', 14035), ('character', 13813), ('watch', 12635), ('love', 11603)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS4JFRAwXSsV",
        "colab_type": "code",
        "outputId": "2cdf8eb3-32f3-4244-d8d4-8d548ae24633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " print(sorted(neg_processed_count.items(), key = lambda x: x[1], reverse = True)[:10])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('movie', 57785), ('film', 44453), ('like', 24027), ('bad', 21515), ('good', 18225), ('time', 15008), ('watch', 14713), ('character', 14153), ('think', 11997), ('look', 11529)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ExTiDhOKVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# References\n",
        "# Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. \n",
        "# The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011)."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}