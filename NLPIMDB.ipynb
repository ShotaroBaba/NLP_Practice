{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPIMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShotaroBaba/NLP_Practice/blob/NLP_smaller_dataset/NLPIMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k02zSz6nO218",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Firstly, download text dataset.:\n",
        "# This time, IMDB comment dataset has been used for the experiment.\n",
        "import os\n",
        "import gensim\n",
        "import requests \n",
        "from gensim.parsing.preprocessing import stem\n",
        "from gensim.parsing.preprocessing import strip_punctuation\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "urlToWiki = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "savedFileName = 'aclImdb_v1.tar.gz'\n",
        "if not os.path.isfile(savedFileName):\n",
        "  with open(savedFileName,'wb') as output:\n",
        "    output.write(requests.get(urlToWiki).content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbtusP0NRdBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "\n",
        "# Extract tar.gz file\n",
        "tarfile.open(savedFileName, \"r:gz\").extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebdtqv55SCMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_test = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/test/neg/\", topdown=False) for x in files if x.endswith(\".txt\") ]\n",
        "pos_test  = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/test/pos/\", topdown=False) for x in files if x.endswith(\".txt\") ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_JXhEaf_iIi",
        "colab_type": "code",
        "outputId": "7073fb9d-e849-4131-be42-4346994dd77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(neg_test[:10])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aclImdb/test/neg/4332_2.txt', 'aclImdb/test/neg/3195_2.txt', 'aclImdb/test/neg/7053_1.txt', 'aclImdb/test/neg/9996_2.txt', 'aclImdb/test/neg/3744_4.txt', 'aclImdb/test/neg/1708_1.txt', 'aclImdb/test/neg/7690_3.txt', 'aclImdb/test/neg/11833_4.txt', 'aclImdb/test/neg/11344_1.txt', 'aclImdb/test/neg/5580_1.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjgCeD_FSNMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_train = [os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/train/neg/\", topdown=False) for x in files if x.endswith(\".txt\")]\n",
        "pos_train  =[os.path.join(root,x) for root, _, files in os.walk(\"aclImdb/train/pos/\", topdown=False) for x in files if x.endswith(\".txt\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9akqc_v3_vwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return texts from path\n",
        "# if the text is too short, then it will omit it. \n",
        "def fetch_text(path):\n",
        "  with open(path) as f:\n",
        "    text = f.read()\n",
        "    if len(text.split()) < 50:\n",
        "      return False\n",
        "    else:\n",
        "      return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbsG16e3_z-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, the files are retrieved as the list of texts.\n",
        "neg_test = list(filter(None, [fetch_text(x) for x in neg_test]))\n",
        "pos_test = list(filter(None, [fetch_text(x) for x in pos_test]))\n",
        "neg_train = list(filter(None, [fetch_text(x) for x in neg_train]))\n",
        "pos_train = list(filter(None, [fetch_text(x) for x in pos_train]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ZA56ONHdFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aggregate all lists into one:\n",
        "\n",
        "all_text = neg_test + pos_test + neg_train + pos_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koI0oWCjSPZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load another necessary libraries and functions\n",
        "import spacy\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "def lemmatize_sentence(text):\n",
        "  doc = nlp(text)\n",
        "  return \" \".join([token.lemma_ for token in doc])\n",
        "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_short\n",
        "from collections import Counter\n",
        "stopwords = gensim.parsing.preprocessing.STOPWORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nde8HDsDCafC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-process these given texts, by removing stop words and lemmatization.\n",
        "all_text_processed = [preprocess_string(lemmatize_sentence(x.lower()), \n",
        "                                        filters = [strip_tags, strip_short, \n",
        "                                                   strip_punctuation, strip_multiple_whitespaces]) for x in all_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2AEh3L-IXHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display how one of them is pre-processed:\n",
        "\n",
        "all_text_processed = [[x for x in str_list if len(x) > 1 and not x in stopwords and not x == \"PRON\"] for str_list in all_text_processed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d38T1sDeJMES",
        "colab_type": "code",
        "outputId": "6a902451-8695-442a-8f57-ad24115084d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(all_text_processed[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['wow', 'watch', 'night', 'mccool', 'yesterday', 'wow', 'major', 'spoilers', 'like', 'summary', 'plot', 'stupid', 'pointless', 'movie', 'tell', 'anybody', 'watch', 'inflict', 'pain', 'glimpse', 'huge', 'chunk', 'plot', 'randy', 'work', 'bar', 'mccool', 'meet', 'woman', 'jewel', 'convince', 'surprisingly', 'sex', 'boyfriend', 'end', 'try', 'rob', 'kill', 'randy', 'cousin', 'detective', 'scene', 'crime', 'fall', 'jewel', 'mascot', 'stupidity', 'use', 'guy', 'want', 'involve', 'dvd', 'player', 'randy', 'hire', 'hit', 'man', 'kill', 'eventually', 'detective', 'kill', 'boyfriend', 'psycho', 'brother', 'hit', 'man', 'jewel', 'seriously', 'leave', 'hardly', 'sex', 'scene', 'nearly', 'pornographic', 'scene', 'liv', 'tyl', 'jewel', 'use', 'hose', 'flaunt', 'sexuality', 'point', 'movie', 'honest', 'think', 'producer', 'director', 'male', 'urge', 'think', 'absolutely', 'uncalled', 'plain', 'stupid', 'watch', 'movie', 'want', 'plot', 'want', 'character', 'care', 'sexy', 'woman', 'flaunt', 'happen', 'movie', 'goodness', 'sake', 'bad', 'fight', 'club', 'bad', 'john', 'goodman', 'detective', 'devote', 'high', 'wonder', 'goodman', 'play', 'outrageously', 'pitiful', 'remember', 'brother', 'art', 'thou', 'reputation', 'notch', 'liv', 'tyl', 'amazing', 'actress', 'lord', 'ring', 'series', 'movie', 'unintelligent', 'slut', 'want', 'way', 'reputation', 'seven', 'notch', 'amazed', 'simply', 'amazed', 'people', 'work', 'hard', 'stupid', 'music', 'absolutely', 'crappy', 'ymca', 'play', 'john', 'goodman', 'character', 'kill', 'fit', 'character', 'totally', 'unlikeable', 'plot', 'stupid', 'conceive', 'man', 'fit', 'genre', 'close', 'pornographic', 'comedy', 'suppose', 'funny', 'wasn', 'think', 'rant', 'let', 'assure', 'right', 'mind', 'want', 'movie', 'lust', 'liv', 'tyl', 'character']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5lU_gwrJW43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionary & BOW:\n",
        "dictionary = Dictionary(all_text_processed)\n",
        "corpus = [dictionary.doc2bow(x) for x in all_text_processed]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvrsNDk3KdCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_imdb = gensim.models.LdaMulticore(corpus, id2word=dictionary, num_topics=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhNIPWTLKivo",
        "colab_type": "code",
        "outputId": "3a15eeac-f1a2-4922-ae81-911fde959e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# You can see that the topic is all about movie and drama series.\n",
        "\n",
        "lda_imdb.show_topics()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.007*\"play\" + 0.006*\"good\" + 0.006*\"film\" + 0.005*\"movie\" + 0.004*\"story\" + 0.004*\"time\" + 0.004*\"love\" + 0.004*\"great\" + 0.004*\"character\" + 0.004*\"man\"'),\n",
              " (1,\n",
              "  '0.038*\"film\" + 0.005*\"like\" + 0.005*\"movie\" + 0.005*\"story\" + 0.005*\"time\" + 0.005*\"scene\" + 0.005*\"character\" + 0.004*\"good\" + 0.004*\"plot\" + 0.003*\"use\"'),\n",
              " (2,\n",
              "  '0.058*\"movie\" + 0.016*\"like\" + 0.015*\"watch\" + 0.015*\"good\" + 0.012*\"film\" + 0.012*\"think\" + 0.011*\"time\" + 0.008*\"bad\" + 0.007*\"great\" + 0.007*\"people\"'),\n",
              " (3,\n",
              "  '0.022*\"film\" + 0.007*\"life\" + 0.006*\"time\" + 0.006*\"story\" + 0.005*\"character\" + 0.005*\"movie\" + 0.005*\"man\" + 0.005*\"good\" + 0.005*\"like\" + 0.004*\"work\"'),\n",
              " (4,\n",
              "  '0.019*\"film\" + 0.016*\"good\" + 0.015*\"movie\" + 0.011*\"like\" + 0.007*\"great\" + 0.007*\"character\" + 0.007*\"scene\" + 0.006*\"look\" + 0.006*\"story\" + 0.006*\"love\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzVwgAkcNVXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count numbers of words in corpus.\n",
        "def count_words_in_corpus(corpus):\n",
        "  count_dict = Counter() \n",
        "  for word_count in corpus:\n",
        "    for key, value in word_count:\n",
        "      count_dict.update({dictionary[key] : value})\n",
        "\n",
        "  return count_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVazZ5iGZsuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_of_words = count_words_in_corpus(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3chj-isJaB4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_count = sorted(count_of_words.items(), key = lambda x: x[1], reverse = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAzsNiu7cb-J",
        "colab_type": "code",
        "outputId": "84fdcb65-4e58-43cd-a5da-ef276fc34b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(\"\\n\".join([str(x) for x in sorted_count[:20]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('movie', 101922)\n",
            "('film', 94644)\n",
            "('like', 43949)\n",
            "('good', 40883)\n",
            "('time', 31142)\n",
            "('character', 27966)\n",
            "('watch', 27346)\n",
            "('bad', 26082)\n",
            "('story', 25046)\n",
            "('think', 23103)\n",
            "('scene', 21149)\n",
            "('great', 19805)\n",
            "('look', 19542)\n",
            "('know', 18990)\n",
            "('people', 18302)\n",
            "('way', 17120)\n",
            "('love', 17003)\n",
            "('play', 16816)\n",
            "('come', 16369)\n",
            "('thing', 16334)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ-P0gxnQEdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_corpus(text_to_be_converted):\n",
        "  all_text_processed = [preprocess_string(lemmatize_sentence(x.lower()), \n",
        "                                          filters = [strip_tags, strip_short, \n",
        "                                                    strip_punctuation, strip_multiple_whitespaces]) for x in text_to_be_converted]\n",
        "  all_text_processed = [[x for x in str_list if len(x) > 1 and not x in stopwords and not x == \"PRON\"] for str_list in all_text_processed]\n",
        "  count_dict = Counter() \n",
        "  for word_list in all_text_processed:\n",
        "    for word in word_list:\n",
        "      count_dict.update({word: 1})                      \n",
        "  return count_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Hzh3ieRNUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count words for both two sentiment.\n",
        "neg = neg_test + neg_train\n",
        "pos = pos_test + pos_train\n",
        "\n",
        "pos_processed_count = create_corpus(pos)\n",
        "neg_processed_count = create_corpus(neg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrD-wNJISc76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ef4f118-8174-4fa9-e0f6-298c687e934d"
      },
      "source": [
        " print(sorted(pos_processed_count.items(), key = lambda x: x[1], reverse = True)[:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('aclimdb', 25000), ('pos', 25000), ('txt', 25000), ('test', 12500), ('train', 12500), ('10', 9733), ('7819', 2), ('1610', 2), ('8541', 2), ('3498', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS4JFRAwXSsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c2841c3-f97b-4dc1-81e2-b15dd0807403"
      },
      "source": [
        " print(sorted(neg_processed_count.items(), key = lambda x: x[1], reverse = True)[:10])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('aclimdb', 25000), ('neg', 25000), ('txt', 25000), ('test', 12500), ('train', 12500), ('4332', 2), ('3195', 2), ('7053', 2), ('9996', 2), ('3744', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ExTiDhOKVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# References\n",
        "# Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. \n",
        "# The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011)."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}